kafka {

  broker.id = 42
  log.dirs = target/kafka-logs
  zookeeper.connect = "localhost:2181"
  listeners = "PLAINTEXT://:9092"
  advertised.listeners = "PLAINTEXT://localhost:9092"

  # Producer
  bootstrap.servers = "localhost:9092"
  key.serializer = "org.apache.kafka.common.serialization.StringSerializer"
  value.serializer = "org.apache.kafka.common.serialization.StringSerializer"
  acks = "all"

  # Consumer
  group.id = "embedded-streaming"
  auto.offset.reset = "earliest"
  enable.auto.commit = "false"
  auto.commit.interval.ms = "1000"
  session.timeout.ms = "10000"
  key.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
  value.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"

  connect {
    bootstrap.servers = "localhost:9092"

    key.converter = "io.confluent.connect.avro.AvroConverter"
    value.converter = "io.confluent.connect.avro.AvroConverter"

    # Nested fields AND top level field ^^^^ are not supported without quotes by HOCON/JSON.
    "key.converter.schemas.enable" = "true"
    "key.converter.schema.registry.url" = "http://localhost:9080"
    "value.converter.schemas.enable" = "true"
    "value.converter.schema.registry.url" = "http://localhost:9080"

    internal.key.converter = "org.apache.kafka.connect.json.JsonConverter"
    internal.value.converter = "org.apache.kafka.connect.json.JsonConverter"
    "internal.key.converter.schemas.enable" = "false"
    "internal.value.converter.schemas.enable" = "false"

    offset.storage.file.filename = "target/kafka-connect/connect.offsets"
    offset.flush.interval.ms = 10000
    rest.port = 8031
  }

  registry {
    kafkastore.connection.url = "localhost:2181"
    port = 9080
  }
}

zookeeper {
  dataDir = target/zookeeper
  clientPort = 2181
  maxClientCnxns = 0
}

redis {
  port = 6379
}